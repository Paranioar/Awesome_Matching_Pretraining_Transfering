Awesome_Cross_Modal_Pretraining_Transfering
===========================================
The tutorial of Cross-Modal Matching / Pretraining / Transfering will be constantly updated for Preliminary Insight !

## ``Logupdate ``

【2024.03.09】 A new section named ***[Large Multi-Modality Model]*** has been added.  
【2023.05.25】 A new section named ***[Parameter-Efficient Finetuning]*** has been added.  
【2021.12.11】 A new section named ***[Video-Text Learning]*** has been added. 
【2021.07.10】 A new section named ***[Vision-Language Pretraining]*** has been added.  

## ``Catalogue ``

* [Methods Summary](./README.md)
    * [Large Multi-Modality Model](./large_mmm.md)
        * [Region Perception-Generation](./large_mmm.md/#region-perception-generation)
        * [Image Perception-Generation](./large_mmm.md/#image-perception-generation)
        * [Video Perception-Generation](./large_mmm.md/#video-perception-generation)
        * [Large Uni-Modality Model](./large_mmm.md/#large-uni-modality-model)
        * [Large Model Distillation](./large_mmm.md/#large-modal-distillation)
        * [Related Survey](./large_mmm.md/#related-survey)
        * [Related Benchmark](./large_mmm.md/#related-benchmark)
    * [Parameter-Efficient Finetuning](./transfer_learning.md)
        * [Parameter-Efficient Method](./transfer_learning.md/#parameter-efficient-method)
        * [Memory-Efficient Method](./transfer_learning.md/#memory-efficient-method)
    * [Vision-Language Pretraining](./pretrained_model.md)
        * [Pretrained Method](./pretrained_model.md/#pretrained-method)
        * [Pretrained Dataset](./pretrained_model.md/#pretrained-dataset)
    * [Conventional Image-Text Matching](./conventional_method.md)
        * [Generic-Feature Extraction](./conventional_method.md/#generic-feature-extraction)
        * [Cross-Modal Interaction](./conventional_method.md/#cross-modal-interaction)
        * [Similarity Measurement](./conventional_method.md/#similarity-measurement)
        * [Uncertainty Learning](./conventional_method.md/#uncertainty-learning)
        * [Noisy Correspondence](./conventional_method.md/#noisy-correspondence)
        * [Commonsense Learning](./conventional_method.md/#commonsense-learning)
        * [Adversarial Learning](./conventional_method.md/#adversarial-learning)
        * [Loss Function](./conventional_method.md/#loss-function)
        * [Un-/Semi-Supervised](./conventional_method.md/#un-supervised-or-semi-supervised)
        * [Zero-/Fewer-Shot](./conventional_method.md/#zero-shot-or-fewer-shot)
        * [Continual Learning](./conventional_method.md/#continual-learning)
        * [Identification Learning](./conventional_method.md/#identification-learning)
        * [Video-Text Learning](https://github.com/danieljf24/awesome-video-text-retrieval)
        * [Scene-Text Learning](./conventional_method.md/#scene-text-learning)
        * [Related Works](./conventional_method.md/#related-works)
        * [Posted in](./conventional_method.md/#posted-in)

* [Peformance Comparison](./performance.md)
    * [Flickr8K](./performance.md/#performance-of-flickr8k)
    * [Flickr30K](./performance.md/#performance-of-flickr30k)
    * [MSCOCO1K](./performance.md/#performance-of-mscoco1k)
    * [MSCOCO5K](./performance.md/#performance-of-mscoco5k)
    * [RSTPReid](./performance.md/#performance-of-rstpreid)
    * [CUHK-PEDES](./performance.md/#performance-of-cuhk-pedes)
    * [ICFG-PEDES](./performance.md/#performance-of-icfg-pedes)
    * [CUB-Flowers](./performance.md/#performance-of-cub-flowers)
    
* [Other Resources](./resource.md/#other-resources)
    * [Large Foundation Model](./resource.md/#large-foundation-model)
    * [Multi-Modality Model](./resource.md/#multi-modality-model)
    * [Transfer Learning](./resource.md/#transfer-learning)
    * [Graph Learning](./resource.md/#graph-learning)
    * [Fewshot Learning](./resource.md/#fewshot-learning)
    

## ``License ``
[MIT license](LICENSE). If any questions, please contact me at r1228240468@gmail.com.
